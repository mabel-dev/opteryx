"""
This fuzzer tests connectors perform the same by issuing the same SQL statement
to multiple connectors and comparing the results.

The test generates random SQL SELECT statements to test various aspects of the
engine such as predicate and projection pushdowns.
"""

import os
import sys

sys.path.insert(1, os.path.join(sys.path[0], "../.."))

import datetime
import random

import pytest
from orso.tools import random_int, random_string
from orso.types import OrsoTypes

import opteryx
from opteryx.utils.formatter import format_sql
from opteryx.connectors import SqlConnector
from opteryx.connectors import CqlConnector
from opteryx.connectors import IcebergConnector
from opteryx.connectors import MongoDbConnector
from opteryx import virtual_datasets
from orso.tools import lru_cache_with_expiry

from tests.tools import create_duck_db, populate_mongo, set_up_iceberg
from tests.tools import is_arm, is_mac, is_windows, skip_if, is_version

TEST_CYCLES: int = 100


TABLES = {
            "planets": {
                "fields": virtual_datasets.planets.schema().columns,
                "connectors": [
                    "$planets",  # virtual data
                    "testdata.planets",  # blob/file storage
                    "'testdata/planets/planets.parquet'",  # file-as-table data
                    "sqlite.planets",  # sqlite
                    "iceberg.planets",  # iceberg
    #                "cockroach.planets",  # cockroach (disabled, field names in lowercase)
    #                "datastax.planets",  # datastax (disabled, dataset not present)
                    "duckdb.planets",  # duckdb
    #                "mongo.planets"  # mongo (disabled, typing system not compatible)
                ]
            },
            "satellites": {
                "fields": virtual_datasets.satellites.schema().columns,
                "connectors": [
                    "$satellites",
                    "testdata.satellites",
                    "'testdata/satellites/satellites.parquet'",
                    "sqlite.satellites"
                ]
            }
    }


@lru_cache_with_expiry
def set_up_connections():

    from cassandra.auth import PlainTextAuthProvider
    from cassandra.cluster import Cluster

    DATA_CATALOG_CONNECTION = os.environ.get("DATA_CATALOG_CONNECTION")
    DATA_CATALOG_STORAGE = os.environ.get("DATA_CATALOG_STORAGE")
    POSTGRES_PASSWORD = os.environ.get("POSTGRES_PASSWORD")
    POSTGRES_USER = os.environ.get("POSTGRES_USER")
    DATASTAX_CLIENT_ID = os.environ.get("DATASTAX_CLIENT_ID")
    DATASTAX_CLIENT_SECRET = os.environ.get("DATASTAX_CLIENT_SECRET")
    COCKROACH_PASSWORD = os.environ.get("COCKROACH_PASSWORD")
    COCKROACH_USER = os.environ.get("COCKROACH_USER")
    COCKROACH_CONNECTION = f"cockroachdb://{COCKROACH_USER}:{COCKROACH_PASSWORD}@redleg-hunter-12763.5xj.cockroachlabs.cloud:26257/opteryx?sslmode=require"
    MONGO_CONNECTION = os.environ.get("MONGODB_CONNECTION")
    MONGO_DATABASE = os.environ.get("MONGODB_DATABASE")

    # Datastax Astra Connection
    # cloud_config = {"secure_connect_bundle": "secure-connect.zip"}
    # auth_provider = PlainTextAuthProvider(DATASTAX_CLIENT_ID, DATASTAX_CLIENT_SECRET)
    # cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)
    # Iceberg
    iceberg_catalog = set_up_iceberg()
    # DuckDB
    create_duck_db()
    # Mongo
    # populate_mongo()

    opteryx.register_store("iceberg", IcebergConnector, catalog=iceberg_catalog)
    #opteryx.register_store("cockroach", SqlConnector, remove_prefix=True, connection=COCKROACH_CONNECTION)
    #opteryx.register_store("datastax", CqlConnector, remove_prefix=True, cluster=cluster)
    opteryx.register_store("duckdb", SqlConnector, remove_prefix=True, connection="duckdb:///planets.duckdb")
    #opteryx.register_store("mongo", MongoDbConnector, database=MONGO_DATABASE, connection=MONGO_CONNECTION, remove_prefix=True)
    opteryx.register_store("sqlite", SqlConnector, remove_prefix=True, connection="sqlite:///testdata/sqlite/database.db")

def random_value(t):
    if t == OrsoTypes.VARCHAR:
        return f"'{random_string(4)}'"
    if t in (OrsoTypes.DATE, OrsoTypes.TIMESTAMP):
        if random.random() < 0.5:
            return f"'{datetime.datetime.now() + datetime.timedelta(seconds=random_int())}'"
        return f"'{(datetime.datetime.now() + datetime.timedelta(seconds=random_int())).date()}'"
    if random.random() < 0.5:
        return random_int()
    return random_int() / 1000


def generate_condition(columns):
    where_column = columns[random.choice(range(len(columns)))]
    while where_column.type in (OrsoTypes.ARRAY, OrsoTypes.STRUCT):
        where_column = columns[random.choice(range(len(columns)))]
    if random.random() < 0.1:
        where_operator = random.choice(["IS", "IS NOT"])
        if where_column.type == OrsoTypes.BOOLEAN:
            where_value = random.choice(["TRUE", "FALSE", "NULL"])
        else:
            where_value = "NULL"
    elif where_column.type == OrsoTypes.VARCHAR and random.random() < 0.5:
        where_operator = random.choice(
            ["LIKE", "ILIKE", "NOT LIKE", "NOT ILIKE", "RLIKE", "NOT RLIKE"]
        )
        where_value = (
            "'" + random_string(8).replace("1", "%").replace("A", "%").replace("6", "_") + "'"
        )
    elif random.random() < 0.8:
        where_operator = random.choice(["==", "<>", "=", "!=", "<", "<=", ">", ">="])
        where_value = f"{str(random_value(where_column.type))}"
    else:
        return f"{where_column.name} BETWEEN {str(random_value(where_column.type))} AND {str(random_value(where_column.type))}" 
    return f"{where_column.name} {where_operator} {where_value}"


def generate_random_sql_select(columns, table):
    # Generate a list of column names to select
    column_list = list(set(random.choices(range(len(columns)), k=max(int(random.random() * len(columns)), 1))))
    column_list = [columns[i] for i in column_list]
    agg_column = None
    is_count_star = False
    # Add DISTINCT keyword with 20% chance
#    if random.random() < 0.2:
#        select_clause = "SELECT DISTINCT " + ", ".join(c.name for c in column_list)
    if random.random() < 0.3:
        distinct = "DISTINCT " if random.random() < 0.1 else ""
        agg_func = random.choice(["MIN", "MAX", "SUM", "AVG", "COUNT", "COUNT_DISTINCT"])
        agg_column = columns[random.choice(range(len(columns)))]
        while agg_func in ("SUM", "AVG") and agg_column.type in (OrsoTypes.ARRAY, OrsoTypes.STRUCT, OrsoTypes.VARCHAR, OrsoTypes.TIMESTAMP, OrsoTypes.DATE):
            agg_column = columns[random.choice(range(len(columns)))]
        while agg_func in ("MIN", "MAX", "COUNT_DISTINCT") and agg_column.type in (OrsoTypes.ARRAY, OrsoTypes.STRUCT):
            agg_column = columns[random.choice(range(len(columns)))]
        select_clause = "SELECT " + distinct + agg_func + "(" + agg_column.name + ")"

        column_list = [c for c in column_list if c.type not in (OrsoTypes.ARRAY, OrsoTypes.STRUCT)]
    elif random.random() < 0.8:
        select_clause = "SELECT " + ", ".join(c.name for c in column_list)
    elif random.random() < 0.5:
        select_clause = "SELECT COUNT(*) "
        is_count_star = True
    else:
        select_clause = "SELECT *"
    # Add table name
    select_clause = select_clause + " FROM " + table
    # Generate a WHERE clause with 70% chance
    if random.random() < 0.7:
        where_clause = generate_condition(columns)
        # add an abitrary number of additional conditions
        while random.random() < 0.3:
            linking_condition = random.choice(["AND", "OR", "AND NOT"])
            where_clause += f" {linking_condition} {generate_condition(columns)} "
        select_clause = f"{select_clause} WHERE {where_clause}"
    # Add GROUP BY clause with 40% chance
    if agg_column and random.random() < 0.4:
        column_list = [c.name for c in column_list]
        select_clause = select_clause + " GROUP BY " + ", ".join(column_list + [agg_column.name])
    # Add ORDER BY clause with 60% chance
    if not agg_column and not is_count_star and random.random() < 0.6:
        order_column = columns[random.choice(range(len(columns)))]
        if order_column.type not in (OrsoTypes.ARRAY, OrsoTypes.STRUCT):
            order_direction = random.choice(["ASC", "DESC", ""])
            select_clause = select_clause + " ORDER BY " + order_column.name + " " + order_direction
    if random.random() < 0.2:
        select_clause = select_clause + " LIMIT " + str(int(random.random() * 10))
    return select_clause


@skip_if(is_arm() or is_windows() or is_mac() or not is_version("3.10"))
@pytest.mark.parametrize("i", range(TEST_CYCLES))
def test_sql_fuzzing_connector_comparisons(i):

    set_up_connections()

    seed = random_int()
    random.seed(seed)

    table_name = random.choice(list(TABLES.keys()))
    table = TABLES[table_name]
    statement = generate_random_sql_select(table["fields"], table_name)
    formatted_statement = format_sql(statement)

    print(formatted_statement)

    print(f"Seed: {seed}, Cycle: {i}")

    try:
        columns = []
        rows = []
        for connector in table["connectors"]:
            print(".", end="", flush=True)
            this_statement = statement.replace(table_name, connector)
            res = opteryx.query(this_statement)
            columns.append(res.columncount)
            rows.append(res.rowcount)
        # Assert all columns are the same
        assert all(col == columns[0] for col in columns), f"Columns are not the same {columns}"
        
        # Assert all rows are the same
        assert all(row == rows[0] for row in rows), f"Rows are not the same {rows}"
        
    except Exception as e:
        import traceback

        print(f"\033[0;31mError in Test Cycle {i+1}, with connector {connector} \033[0m: {type(e)}")
        print(traceback.print_exc())
        # Log failing statement and error for analysis
        assert False, f"Error in Test Cycle {i+1}, with connector {connector}: {type(e)} \n {format_sql(this_statement)}"
    print()

if __name__ == "__main__":  # pragma: no cover

    for i in range(TEST_CYCLES):
        test_sql_fuzzing_connector_comparisons(i)

    print("✅ okay\n")
